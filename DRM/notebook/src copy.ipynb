{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf4965ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0ad6ec",
   "metadata": {},
   "source": [
    "## Deep Ritz Method for Solving PDEs  \n",
    "The Deep Ritz Method is a neural network-based approach for solving partial differential equations (PDEs) by reformulating the problem as a variational problem. This method leverages the expressive power of deep neural networks to approximate the solution of PDEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6426aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04108f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_interior(n_samples):\n",
    "    \"\"\"Sample points in the interior of the domain [0, 1] x [0, 1].\"\"\"\n",
    "    x = np.random.uniform(0, 1, (n_samples, 1))\n",
    "    y = np.random.uniform(0, 1, (n_samples, 1))\n",
    "    return torch.tensor(np.hstack((x, y)), dtype=torch.float32).to(device)\n",
    "\n",
    "def sample_boundary(n_samples, require_normals=False):\n",
    "    \"\"\"\n",
    "    Sample points and normal vectorson the boundary of the domain [0, 1] x [0, 1].\n",
    "    Returns:\n",
    "        points: Tensor of shape (n_samples, 2) containing boundary points.\n",
    "        normals: Tensor of shape (n_samples, 2) containing normal vectors at the boundary points.\n",
    "    \"\"\"\n",
    "    n_samples_per_side = n_samples // 4\n",
    "    # Four sides of the square\n",
    "    left = np.stack((np.zeros((n_samples_per_side, 1)), np.random.uniform(0, 1, (n_samples_per_side, 1))), axis=1)\n",
    "    right = np.stack((np.ones((n_samples_per_side, 1)), np.random.uniform(0, 1, (n_samples_per_side, 1))), axis=1)\n",
    "    bottom = np.stack((np.random.uniform(0, 1, (n_samples_per_side, 1)), np.zeros((n_samples_per_side, 1))), axis=1)\n",
    "    top = np.stack((np.random.uniform(0, 1, (n_samples_per_side, 1)), np.ones((n_samples_per_side, 1))), axis=1)\n",
    "    \n",
    "    #stack all boundary points\n",
    "    points = np.vstack((left, right, bottom, top))\n",
    "    normals = None\n",
    "    \n",
    "    if require_normals:\n",
    "        #normal vectors \n",
    "        normals = np.vstack([\n",
    "            np.tile([-1, 0], (n_samples_per_side, 1)),  # left\n",
    "            np.tile([1, 0], (n_samples_per_side, 1)),\n",
    "            np.tile([0, -1], (n_samples_per_side, 1)),  # bottom\n",
    "            np.tile([0, 1], (n_samples_per_side, 1))   # top\n",
    "        ])\n",
    "    \n",
    "    return (\n",
    "        torch.tensor(points, dtype=torch.float32).to(device),\n",
    "        torch.tensor(normals, dtype=torch.float32).to(device) if require_normals else None\n",
    "    )\n",
    "       \n",
    "\n",
    "def generate_samples(n_interior, n_boundary, require_normals=False):\n",
    "    \"\"\"Generate interior and boundary samples.\"\"\"\n",
    "    interior_points = sample_interior(n_interior)\n",
    "    boundary_points, boundary_normals = sample_boundary(n_boundary, require_normals)\n",
    "    return interior_points, boundary_points, boundary_normals\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3744e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47d49d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class U_FCN(nn.Module):\n",
    "    def __init__(self,in__features : int = 2, out_features : int = 1, hidden_dims : list = [8,16,32,32,16,8]):\n",
    "        super(U_FCN,self).__init__()\n",
    "        layers = []\n",
    "        input_dim = in__features\n",
    "        for h_dim in hidden_dims:\n",
    "            # layers.append(nn.BatchNorm1d(input_dim))\n",
    "            layers.append(nn.Linear(input_dim, h_dim))\n",
    "            layers.append(nn.Tanh())\n",
    "            # layers.append(nn.Dropout(p=0.2))\n",
    "            input_dim = h_dim\n",
    "        layers.append(nn.Linear(input_dim, out_features))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    def forward(self,x):\n",
    "        return self.network(x)\n",
    "    \n",
    "# ---------------biharmonic operator ---------------\n",
    "\n",
    "def biharmonic_operator(u : torch.Tensor,x : torch.Tensor):\n",
    "    \"\"\"\n",
    "    Compute Δ²u = Laplacian(Laplacian(u)) using autograd.\n",
    "    x : torch.Tensor (N,2) with required_grad = True\n",
    "    return : torch.Tensor (N,1)\n",
    "    \"\"\"\n",
    "    if not x.requires_grad:\n",
    "        x.requires_grad = True\n",
    "    grad_u = torch.autograd.grad(u,x,grad_outputs=torch.ones_like(u),create_graph=True)[0]\n",
    "    u_x = grad_u[:,0:1]\n",
    "    u_y = grad_u[:,1:2]\n",
    "    u_xx = torch.autograd.grad(u_x,x,grad_outputs=torch.ones_like(u_x),create_graph=True)[0][:,0:1]\n",
    "    u_yy = torch.autograd.grad(u_y,x,grad_outputs=torch.ones_like(u_y),create_graph=True)[0][:,1:2]\n",
    "    lap_u = u_xx + u_yy\n",
    "    \n",
    "    grad_lap_u = torch.autograd.grad(lap_u,x,grad_outputs=torch.ones_like(lap_u),create_graph=True)[0]\n",
    "    lap_u_x = grad_lap_u[:,0:1]\n",
    "    lap_u_y = grad_lap_u[:,1:2]\n",
    "    lap_u_xx = torch.autograd.grad(lap_u_x,x,grad_outputs=torch.ones_like(lap_u_x),create_graph=True)[0][:,0:1]\n",
    "    lap_u_yy = torch.autograd.grad(lap_u_y,x,grad_outputs=torch.ones_like(lap_u_y),create_graph=True)[0][:,1:2]\n",
    "    \n",
    "    return lap_u_xx + lap_u_yy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad695e9",
   "metadata": {},
   "source": [
    "### Penalized Energy Functional (P2)\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_\\lambda(v)\n",
    "= \n",
    "\\frac{1}{2}\\int_{\\Omega} \\lvert D^{2} v \\rvert^{2}\\, dx\n",
    "\\;-\\;\n",
    "\\int_{\\Omega} f\\, v\\, dx\n",
    "\\;-\\;\n",
    "\\int_{\\partial\\Omega} g_{2}\\, \\frac{\\partial v}{\\partial n}\\, ds\n",
    "\\;+\\;\n",
    "\\frac{\\lambda}{2}\\int_{\\partial\\Omega} (v - g_{1})^{2}\\, ds.  \n",
    "\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- $D^2 v$ is the Hessian matrix of $v$.  \n",
    "- $|D^2 v|^2 = \\sum_{i,j} \\left( \\frac{\\partial^2 v}{\\partial x_i \\partial x_j} \\right)^2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4836f11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e47e8f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hassian( u : torch.Tensor, x : torch.Tensor):\n",
    "    \"\"\"\n",
    "    Compute the Hessian matrix of u with respect to x.\n",
    "    u : torch.Tensor (N,1)\n",
    "    x : torch.Tensor (N,2) with required_grad = True\n",
    "    return : torch.Tensor (N,2,2)\n",
    "    \"\"\"\n",
    "    if not x.requires_grad:\n",
    "        x.requires_grad = True\n",
    "    grad_u = torch.autograd.grad(u,x,grad_outputs=torch.ones_like(u),create_graph=True)[0]\n",
    "    u_x = grad_u[:,0:1]\n",
    "    u_y = grad_u[:,1:2]\n",
    "    \n",
    "    u_xx = torch.autograd.grad(u_x,x,grad_outputs=torch.ones_like(u_x),create_graph=True)[0][:,0:1]\n",
    "    u_xy = torch.autograd.grad(u_x,x,grad_outputs=torch.ones_like(u_x),create_graph=True)[0][:,1:2]\n",
    "    u_yx = torch.autograd.grad(u_y,x,grad_outputs=torch.ones_like(u_y),create_graph=True)[0][:,0:1]\n",
    "    u_yy = torch.autograd.grad(u_y,x,grad_outputs=torch.ones_like(u_y),create_graph=True)[0][:,1:2]\n",
    "    \n",
    "    hessian = torch.stack([\n",
    "        torch.cat([u_xx, u_xy], dim=1),\n",
    "        torch.cat([u_yx, u_yy], dim=1)\n",
    "    ], dim=1)  # Shape (N, 2, 2)\n",
    "    \n",
    "    return hessian\n",
    "\n",
    "def compute_normal_derivative(u: torch.Tensor, x: torch.Tensor, normals: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Compute the normal derivative of u at boundary points.\n",
    "    u : torch.Tensor (N,1)\n",
    "    x : torch.Tensor (N,2) with required_grad = True\n",
    "    normals : torch.Tensor (N,2)\n",
    "    return : torch.Tensor (N,1)\n",
    "    \"\"\"\n",
    "    if not x.requires_grad:\n",
    "        x.requires_grad = True\n",
    "    grad_u = torch.autograd.grad(u,x,grad_outputs=torch.ones_like(u),create_graph=True)[0]\n",
    "    normal_derivative = torch.sum(grad_u * normals, dim=1, keepdim=True)\n",
    "    return normal_derivative\n",
    "\n",
    "def compute_first_normal_derivative(u: torch.Tensor, x: torch.Tensor, normal: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Compute the first normal derivative ∂u/∂n using autograd.\n",
    "    u : torch.Tensor (N,1) with required_grad = True\n",
    "    x : torch.Tensor (N,2)\n",
    "    normal : torch.Tensor (N,2)\n",
    "    return : torch.Tensor (N,1)\n",
    "    \"\"\"\n",
    "    if not x.requires_grad:\n",
    "        x.requires_grad = True\n",
    "    \n",
    "    grad_u = torch.autograd.grad(u,x,grad_outputs=torch.ones_like(u),create_graph=True)[0]\n",
    "    du_dn = torch.sum(grad_u * normal, dim=1, keepdim=True) #TODO we could use dot product here\n",
    "    \n",
    "    return du_dn\n",
    "\n",
    "\n",
    "def compute_second_normal_derivative(u: torch.Tensor, x: torch.Tensor, normal: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Compute the second normal derivative ∂²u/∂n² using autograd.\n",
    "    u : torch.Tensor (N,1) with required_grad = True\n",
    "    x : torch.Tensor (N,2)\n",
    "    normal : torch.Tensor (N,2)\n",
    "    return : torch.Tensor (N,1)\n",
    "    \"\"\"\n",
    "    if not x.requires_grad:\n",
    "        x.requires_grad = True\n",
    "    \n",
    "    grad_u = torch.autograd.grad(u,x,grad_outputs=torch.ones_like(u),create_graph=True)[0]\n",
    "    du_dn = torch.sum(grad_u * normal, dim=1, keepdim=True) #TODO we could use dot product here\n",
    "    \n",
    "    grad_du_dn = torch.autograd.grad(du_dn,x,grad_outputs=torch.ones_like(du_dn),create_graph=True)[0]\n",
    "    d2u_dn2 = torch.sum(grad_du_dn * normal, dim=1, keepdim=True) #similarily\n",
    "    \n",
    "    return d2u_dn2\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1ad22cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_solution(pts):\n",
    "    \"\"\" \n",
    "    pts : torch.Tensor with shape (N,2)\n",
    "    \"\"\"\n",
    "    if not isinstance(pts,torch.Tensor):\n",
    "        pts = torch.Tensor(pts,dtype = torch.float32)\n",
    "    pts = pts.to(dtype=torch.float32, device=pts.device)\n",
    "    C = 1.0/(2*torch.pi**2)\n",
    "    sol = C * torch.sin(torch.pi*pts[:,0]) * torch.sin(torch.pi*pts[:,1])\n",
    "     \n",
    "    return sol.unsqueeze(-1)\n",
    "\n",
    "def func(pts):\n",
    "    \"\"\" \n",
    "    pts : torch.Tensor with shape (N,2)\n",
    "    \"\"\"\n",
    "    if not isinstance(pts,torch.Tensor):\n",
    "        pts = torch.Tensor(pts,dtype = torch.float32)\n",
    "    pts = pts.to(dtype=torch.float32, device=pts.device)\n",
    "    f =  2.0*torch.pi**2 * torch.sin(torch.pi* pts[:,0]) * torch.sin(torch.pi * pts[:,1])\n",
    "    return f.unsqueeze(-1)\n",
    "\n",
    "\n",
    "def g1(pts):\n",
    "    \"\"\" \n",
    "    g1(pts) = u same as the neural apporximator\n",
    "    \"\"\"\n",
    "    return true_solution(pts)\n",
    "\n",
    "def g2(pts,normals):\n",
    "    \"\"\" \n",
    "    g2(pts,normals) = d2u/dn2\n",
    "    \"\"\"\n",
    "    u = true_solution(pts)\n",
    "    # or else we can call the compute_second_normal_derivative function\n",
    "    d2u_dn2 = normals.unsqueeze(-1) @ compute_hassian(u, pts) @ normals.unsqueeze(-1)\n",
    "    return d2u_dn2.squeeze(-1)\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16acd40",
   "metadata": {},
   "source": [
    "### Monte–Carlo Approximation of the Penalized Energy (P2)\n",
    "\n",
    "Let  \n",
    "- $\\{x_i\\}_{i=1}^N \\subset \\Omega$ be interior collocation points,  \n",
    "- $\\{y_j\\}_{j=1}^M \\subset \\partial\\Omega$ be boundary collocation points,  \n",
    "- $|\\Omega|$ the measure of the domain,  \n",
    "- $|\\partial\\Omega|$ the measure of the boundary.\n",
    "\n",
    "Then the Monte–Carlo approximation of $\\mathcal{L}_\\lambda(v)$ is\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\lambda}^{\\text{MC}}(v)\n",
    "=\n",
    "\\frac{1}{2}\\frac{|\\Omega|}{N}\n",
    "\\sum_{i=1}^N \\big|D^2 v(x_i)\\big|^2\n",
    "\\;-\\;\n",
    "\\frac{|\\Omega|}{N}\n",
    "\\sum_{i=1}^N f(x_i)\\, v(x_i)\n",
    "\\;-\\;\n",
    "\\frac{|\\partial\\Omega|}{M}\n",
    "\\sum_{j=1}^M g_2(y_j)\\, \n",
    "\\frac{\\partial v}{\\partial n}(y_j)\n",
    "\\;+\\;\n",
    "\\frac{\\lambda}{2}\\frac{|\\partial\\Omega|}{M}\n",
    "\\sum_{j=1}^M \\left(v(y_j) - g_1(y_j)\\right)^2 .\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65e45430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interior_loss(model, pts):\n",
    "    \"\"\"\n",
    "    Compute the interior loss for the biharmonic equation Δ²u = f.\n",
    "    model : neural network model\n",
    "    pts : torch.Tensor (N,2)\n",
    "    return : torch.Tensor (1,)\n",
    "    \"\"\"\n",
    "    if not pts.requires_grad:\n",
    "        pts.requires_grad = True\n",
    "        \n",
    "    u = model(pts)\n",
    "    hessian = compute_hassian(u, pts)\n",
    "    frobenius_norm_squared = torch.sum(hessian**2, dim=(1, 2))\n",
    "    source_term = func(pts)*u #shape (N,1)\n",
    "    loss_interior = torch.mean(0.5 * frobenius_norm_squared - source_term.squeeze(-1))\n",
    "    return loss_interior\n",
    "\n",
    "def boundary_loss(model, pts, normals):\n",
    "    \"\"\"\n",
    "    Compute the boundary loss for the biharmonic equation with boundary conditions.\n",
    "    model : neural network model\n",
    "    pts : torch.Tensor (N,2)\n",
    "    normals : torch.Tensor (N,2)\n",
    "    return : torch.Tensor (1,)\n",
    "    \"\"\"\n",
    "    if not pts.requires_grad:\n",
    "        pts.requires_grad = True    \n",
    "    u = model(pts)\n",
    "    u_true = g1(pts)\n",
    "    loss_bc1 = F.mse_loss(u, u_true)\n",
    "    \n",
    "    neumann_term = g2(pts, normals)*compute_first_normal_derivative(u, pts, normals)\n",
    "    loss_bc2 = torch.mean(neumann_term)\n",
    "    loss_boundary = loss_bc1 - loss_bc2\n",
    "    return loss_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ddf6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, n_interior = 1000):\n",
    "    \"\"\"\n",
    "    Validate the model by computing the L2 error against the true solution.\n",
    "    model : neural network model\n",
    "    n_interior : int, number of interior points for validation\n",
    "    n_boundary : int, number of boundary points for validation\n",
    "    return : float, L2 error\n",
    "    \"\"\"\n",
    "    interior_pts, boundary_pts, _ = generate_samples(n_interior, n_boundary)\n",
    "    all_pts = torch.cat([interior_pts, boundary_pts], dim=0)\n",
    "    \n",
    "    u_pred = model(all_pts).detach()\n",
    "    u_true = true_solution(all_pts).detach()\n",
    "    \n",
    "    l2_error = torch.sqrt(torch.mean((u_pred - u_true) ** 2)).item()\n",
    "    return l2_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b3eb21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "def train1(\n",
    "    model,\n",
    "    optimizer,\n",
    "    log_var_interior : torch.nn.Parameter,\n",
    "    log_var_boundary : torch.nn.Parameter,\n",
    "    epochs : int = 1000,\n",
    "    n_interior : int = 1000,\n",
    "    n_boundary : int = 400,\n",
    "    print_interval : int = 100,\n",
    "    save_path : str = None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Train the model using the Deep Ritz Method for the biharmonic equation.\n",
    "    model : neural network model\n",
    "    optimizer : torch.optim.Optimizer\n",
    "    log_var_interior : torch.nn.Parameter, log variance for interior loss\n",
    "    log_var_boundary : torch.nn.Parameter, log variance for boundary loss\n",
    "    epochs : int, number of training epochs\n",
    "    n_interior : int, number of interior points per epoch\n",
    "    n_boundary : int, number of boundary points per epoch\n",
    "    print_interval : int, interval for printing training progress\n",
    "    save_path : str, path to save the trained model\n",
    "    \"\"\"\n",
    "    lossses = []\n",
    "    interior_losses = []\n",
    "    boundary_losses = []\n",
    "    device = next(model.parameters()).device\n",
    "    pbar = tqdm(range(1,epochs + 1), desc=\"Training\", unit=\"epoch\")\n",
    "    for epoch in pbar:\n",
    "        model.train()\n",
    "        interior_pts, boundary_pts, boundary_normals = generate_samples(n_interior, n_boundary, require_normals=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        interior_pts.requires_grad = True\n",
    "        boundary_pts.requires_grad = True        \n",
    "        loss_interior = interior_loss(model, interior_pts)\n",
    "        loss_boundary = boundary_loss(model, boundary_pts, boundary_normals)\n",
    "        \n",
    "        precision_interior = torch.exp(-log_var_interior)\n",
    "        precision_boundary = torch.exp(-log_var_boundary)\n",
    "        #! total loss with uncertainty weighting\n",
    "        total_loss = 0.5*(precision_interior * loss_interior + log_var_interior + precision_boundary * loss_boundary + log_var_boundary)\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        lossses.append(total_loss.item())\n",
    "        interior_losses.append(loss_interior.item())\n",
    "        boundary_losses.append(loss_boundary.item())\n",
    "        \n",
    "        if epoch % print_interval == 0 or epoch == 1:\n",
    "            # val_error = validation(model)\n",
    "            pbar.set_postfix({\n",
    "                'Total Loss': total_loss.item(),\n",
    "                'Interior Loss': loss_interior.item(),\n",
    "                'Boundary Loss': loss_boundary.item(),\n",
    "                'precision_interior': precision_interior.item(),\n",
    "                'precision_boundary': precision_boundary.item()\n",
    "            })\n",
    "        if epoch % (epochs // 10) == 0:\n",
    "            val_error = validation(model)\n",
    "            print(f\"Validation L2 Error at epoch {epoch}: {val_error}\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba804675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.makedirs('biharmonic_DRM',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3084545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = U_FCN(in__features=2,out_features=1,hidden_dims=[16,32,64,128,128,64,32,16]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "log_var_interior = torch.nn.Parameter(torch.tensor(0.0,device= device))\n",
    "log_var_boundary = torch.nn.Parameter(torch.tensor(0.0,device= device))\n",
    "optimizer.add_param_group({'params': [log_var_interior, log_var_boundary],'lr' : 1e-5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23115b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/5000 [00:00<?, ?epoch/s]c:\\Users\\kumar\\venvs\\py312\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\cuda\\CublasHandlePool.cpp:180.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Training:   0%|          | 0/5000 [00:00<?, ?epoch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1600x1 and 2x16)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m losses, interior_losses, boundary_losses = \u001b[43mtrain1\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_var_interior\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_var_boundary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_interior\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_boundary\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m800\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_interval\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbiharmonic_DRM/biharmonic_drm_model.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mtrain1\u001b[39m\u001b[34m(model, optimizer, log_var_interior, log_var_boundary, epochs, n_interior, n_boundary, print_interval, save_path)\u001b[39m\n\u001b[32m     37\u001b[39m boundary_pts.requires_grad = \u001b[38;5;28;01mTrue\u001b[39;00m        \n\u001b[32m     38\u001b[39m loss_interior = interior_loss(model, interior_pts)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m loss_boundary = \u001b[43mboundary_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundary_pts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundary_normals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m precision_interior = torch.exp(-log_var_interior)\n\u001b[32m     42\u001b[39m precision_boundary = torch.exp(-log_var_boundary)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mboundary_loss\u001b[39m\u001b[34m(model, pts, normals)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pts.requires_grad:\n\u001b[32m     27\u001b[39m     pts.requires_grad = \u001b[38;5;28;01mTrue\u001b[39;00m    \n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m u = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m u_true = g1(pts)\n\u001b[32m     30\u001b[39m loss_bc1 = F.mse_loss(u, u_true)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kumar\\venvs\\py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1740\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1739\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1740\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kumar\\venvs\\py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1750\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1753\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1754\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mU_FCN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kumar\\venvs\\py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1740\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1739\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1740\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kumar\\venvs\\py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1750\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1753\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1754\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kumar\\venvs\\py312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kumar\\venvs\\py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1740\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1739\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1740\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kumar\\venvs\\py312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1750\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1753\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1754\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kumar\\venvs\\py312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (1600x1 and 2x16)"
     ]
    }
   ],
   "source": [
    "losses, interior_losses, boundary_losses = train1(\n",
    "    model,\n",
    "    optimizer,\n",
    "    log_var_interior,\n",
    "    log_var_boundary,\n",
    "    epochs = 5000,\n",
    "    n_interior = 2000,\n",
    "    n_boundary = 800,\n",
    "    print_interval = 100,\n",
    "    save_path = 'biharmonic_DRM/biharmonic_drm_model.pth'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a362925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312 (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
